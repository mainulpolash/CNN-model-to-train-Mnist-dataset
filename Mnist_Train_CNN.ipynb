{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Problem Definition: I am going to implement a model from scratch and train it with Mnist dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dataset: Mnist dataset is a famous dataset for image classification where we need to classify hand-written digits (0-9) from image data. The data contain 60000 samples for train and 10000 samples for test. The images all have the same square size of 28×28 pixels, and that the images are grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# First we will load the data using tensorflow\n",
    "#I download download the data from the internet. In the datset, images are representing as 28*28 matrrix but we are going to flatten it into a 1-D vector (28*28=784,1). So we first need to d.load the data and reshape it into the vector by the following code:\n",
    "    \n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "But you know we have TensorFlow who will do the following task for us in Just one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#I am going to design a 2D convolution neural network (CNN) for this data. I choose CNN because it focuses to the neighbouring neurons only rather than connect to all the neurons. This is how our brain detect a object. Based on this principle of human vision, this CNN model is designed. As the input images have 2 dimension - Height and width, I choose to design a 2-D convolution. We are considering the color channel as ‘1’ as the dataset doesn't contain any colored images.\n",
    "\n",
    "#To do so, I need some helper function for building a CNN. I am defining the functions below which will initial the weight and bias. In bias I used constant distribution and for weight I use truncated normal distribution which gives random values where mean is close 0 as well as the values individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_bias(shape):\n",
    "    initialize_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initialize_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(shape):\n",
    "    initialize_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initialize_random_dist)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now I will create a 2D convolution using built-in conv2d from TF. It takes two inputs. x represents the input image and w represents the filter. \n",
    "-> x is a 4-D tensor (Images, height, width, color_channel)\n",
    "-> w is 2-D tensor (filter height, filter width, in channel, out channel)\n",
    "\n",
    "# This function do the following: \n",
    "    1. Run the filters (3 by 3) over the input images with the stride size which is 1 for this network. \n",
    "    2. Doing the 0 padding to determine the edge of each picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now we need to define the Pooling. Pooling is to take a matrix and slide it over the input image like filter. And the taka max value. This dropout lots of information about the original image which we do not need for this classification. I am going to take a 2 by 2 pooling. \n",
    "\n",
    "    --> ksize is the size of the window for the each dimension of the input 4-D Tensor. I want to do the pooling only along the height and width of the images that's why it's value i set [1,2,2,1]. I don't need to do pooling for image and channel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now I will define my layers for the models. Following is the convolutional layer. Shape depends on the size of the image’s and the dimension of the tensors. I am going to use `relu` as the activation function. Using the conv2d function, we'll return an actual convolutional layer here that uses an ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = initialize_weights(shape)\n",
    "    b = initialize_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# x label has a shape 28*28 = 784\n",
    "# y label has a shape of 10 (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now start to declare my layers. In the following, I again reshape the flatten vector into a 28 by 28 image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now I will define my convoulutional layers. \n",
    "-->I choose a 4 by 4 convolutional layer (filter), I choose total 32 filters which are goint to the next input. The convolutional layer will compute total 32 features each having a filter size of 5 by 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convolutional_layer1 = convolutional_layer(input_image, shape =[4,4,1,32])\n",
    "pooling_layer1 = max_pool(convolutional_layer1)\n",
    "convolutional_layer2 = convolutional_layer(pooling_layer1, shape =[4,4,32,64])\n",
    "pooling_layer2 = max_pool(convolutional_layer2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now I will flatten the convolutional layers so that I can connect it to fully connected layer. After appling 2 by 2 pooling over the 28 by 28 images we will get a 7 by 7 image. (28/2)/2 =7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(pooling_layer2,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(fully_connected_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. We will do drop-out to prevent over-fitting. Dropping some neurons will prevent us from catching the internal noise of the input. Tensorflow have a nice function to do this task, I am going to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holding_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=holding_prob)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Finally I will predict the label (0-9) from the input layer sending the input output from the dropout layer and the size 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prediction =fully_connected_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I will use cross entropy from TensorFlow\n",
    "# I will use adam optimizer with learning rate of 0.001 from TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_prediction))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now I will initialize all my variables usingS TensorFlow's global initialization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Now I am going to create the session for training. As my pc is super slow I will show for couple of steps to see whether it is working or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.1229\n",
      "\n",
      "\n",
      "Currently on step 5\n",
      "Accuracy is:\n",
      "0.1611\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 10\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    \n",
    "    for i in range(step):\n",
    "        input_x , input_y = mnist.train.next_batch(100)\n",
    "        session.run(train,feed_dict={x:input_x,y:input_y,holding_prob:0.5})\n",
    "    \n",
    "        if i%5 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_prediction,1),tf.argmax(y,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(session.run(acc,feed_dict={x:mnist.test.images,y:mnist.test.labels,holding_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Looks like it is working. I have implemented my model just using as a simple CNN model for the time constarint and slow pc of mine. This dataset is very simple datset and it is giving accuracy of around 98 using just basic CNN, that's I didn't try much. And we know that if the dataset is not evenly districuted then accuracy is not a good metric to measure performace. I can try to evaluate the model with other metric also. And during the flatteing the image into 1-D vector, some information gone vanished such as the information about two neighbouring pixels, if I somehow preserve that information I could have get something special. Otherwise, I would say it works better, if have enough time, we would train the whole sample and see whether it reaches to 99% accuracy rate which is the current state of the art value for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
